# tools/parse_bref_play_by_play_table_to_phase_csv.py
# Parses Basketball-Reference WNBA "Play-by-Play Table" HTML (your data.html)
# and writes a clean CSV keyed by playerId, preferring TOT rows for multi-team players.

from __future__ import annotations

import argparse
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import pandas as pd


def slugify(text: str) -> str:
    t = (text or "").strip().lower()
    t = re.sub(r"[^a-z0-9]+", "_", t).strip("_")
    return t or "unknown"


def dedup_columns(cols: List[str]) -> List[str]:
    """
    Pandas read_html can yield duplicate column names (e.g., G, MP, Shoot, Off.).
    We convert duplicates to col__2, col__3, etc.
    """
    seen: Dict[str, int] = {}
    out = []
    for c in cols:
        c = (str(c) if c is not None else "").strip()
        if c == "":
            c = "blank"
        if c in seen:
            seen[c] += 1
            out.append(f"{c}__{seen[c]}")
        else:
            seen[c] = 1
            out.append(c)
    return out


def to_number(x):
    if x is None:
        return None
    s = str(x).strip()
    if s in ("", "—", "-", "–"):
        return None
    # remove commas
    s = s.replace(",", "")
    try:
        if "." in s:
            return float(s)
        return int(s)
    except ValueError:
        return None


def load_bref_pbp_table(html_path: Path) -> pd.DataFrame:
    # This HTML has a caption "Play-by-Play Table" and a typical BRef share table.
    tables = pd.read_html(str(html_path), flavor="lxml")
    if not tables:
        raise RuntimeError("No tables found in HTML.")

    # Heuristic: pick the one with Player/Team/Pos in the header
    best = None
    for t in tables:
        cols = [str(c).strip() for c in t.columns]
        if any("Player" in c for c in cols) and any("Team" in c for c in cols) and any("Pos" in c for c in cols):
            best = t
            break

    if best is None:
        # fall back to first
        best = tables[0]

    df = best.copy()

    # Flatten multiindex headers if present
    if isinstance(df.columns, pd.MultiIndex):
        # take the last level, BRef often uses grouped headers
        df.columns = [c[-1] for c in df.columns.values]

    df.columns = dedup_columns([str(c) for c in df.columns])

    # Drop obvious spacer columns (blank / blank__2 etc)
    drop_cols = [c for c in df.columns if c.lower().startswith("blank")]
    if drop_cols:
        df = df.drop(columns=drop_cols, errors="ignore")

    # Normalize key columns
    rename_map = {}
    for c in df.columns:
        cl = c.strip().lower()
        if cl == "player":
            rename_map[c] = "playerName"
        elif cl == "team":
            rename_map[c] = "teamId"
        elif cl == "pos":
            rename_map[c] = "pos"
        elif cl == "g":
            # BRef pbp table has G twice (season totals + on-court context) — keep first as games
            # if we see duplicates, pandas will name them G, G__2
            if c == "G":
                rename_map[c] = "g"
            elif c.startswith("G__"):
                rename_map[c] = "g_oncourt"
        elif cl == "mp":
            if c == "MP":
                rename_map[c] = "mp"
            elif c.startswith("MP__"):
                rename_map[c] = "mp_oncourt"

        # +/- per 100 poss
        elif cl == "oncourt":
            rename_map[c] = "onCourt_plusMinus_per100"
        elif cl == "on-off":
            rename_map[c] = "onOff_plusMinus_per100"

        # turnover types
        elif cl == "badpass":
            rename_map[c] = "tov_badPass"
        elif cl == "lostball":
            rename_map[c] = "tov_lostBall"
        elif cl == "shoot":
            # appears in turnovers + fouls drawn/committed sections, duplicates will be Shoot, Shoot__2, Shoot__3
            # We will map by order after rename_map, below.
            pass
        elif cl == "off.":
            pass

        # misc
        elif cl == "pga":
            rename_map[c] = "misc_pga"    # points generated by assists in BRef tables
        elif cl == "and1":
            rename_map[c] = "misc_and1"
        elif cl == "blkd":
            rename_map[c] = "misc_blkd"

    df = df.rename(columns=rename_map)

    # Now map the repeating "Shoot" / "Off." columns by their occurrence order.
    shoot_cols = [c for c in df.columns if c.startswith("Shoot")]
    off_cols = [c for c in df.columns if c.startswith("Off.")]

    # From the HTML header order (Turnovers -> Fouls Committed -> Fouls Drawn):
    # Turnovers: Shoot, Off.  (these are actually turnover counts on shots/offs? BRef labels them in the shared table)
    # Fouls Committed: Shoot, Off.
    # Fouls Drawn: Shoot, Off.
    # So we expect 3 pairs.
    shoot_cols_sorted = sorted(shoot_cols, key=lambda x: (len(x), x))
    off_cols_sorted = sorted(off_cols, key=lambda x: (len(x), x))

    # Better: keep original order as in df.columns
    shoot_cols_sorted = [c for c in df.columns if c.startswith("Shoot")]
    off_cols_sorted = [c for c in df.columns if c.startswith("Off.")]

    def safe_get(lst, idx):
        return lst[idx] if idx < len(lst) else None

    # Pair 0: turnovers
    if safe_get(shoot_cols_sorted, 0):
        df = df.rename(columns={shoot_cols_sorted[0]: "tov_shoot"})
    if safe_get(off_cols_sorted, 0):
        df = df.rename(columns={off_cols_sorted[0]: "tov_offensiveFoulOrOther"})

    # Pair 1: fouls committed
    if safe_get(shoot_cols_sorted, 1):
        df = df.rename(columns={shoot_cols_sorted[1]: "foulsCommitted_shooting"})
    if safe_get(off_cols_sorted, 1):
        df = df.rename(columns={off_cols_sorted[1]: "foulsCommitted_offensive"})

    # Pair 2: fouls drawn
    if safe_get(shoot_cols_sorted, 2):
        df = df.rename(columns={shoot_cols_sorted[2]: "foulsDrawn_shooting"})
    if safe_get(off_cols_sorted, 2):
        df = df.rename(columns={off_cols_sorted[2]: "foulsDrawn_offensive"})

    # Clean types
    for c in df.columns:
        if c in ("playerName", "teamId", "pos"):
            continue
        df[c] = df[c].map(to_number)

    # Drop rows with missing player/team
    df["playerName"] = df["playerName"].astype(str).str.strip()
    df["teamId"] = df["teamId"].astype(str).str.strip()
    df = df[(df["playerName"] != "") & (df["teamId"] != "")].copy()

    return df


def load_player_id_map(players_csv: Path) -> Dict[str, str]:
    """
    Maps normalized playerName -> playerId from your data/players.csv
    """
    if not players_csv.exists():
        return {}
    p = pd.read_csv(players_csv)
    if "playerId" not in p.columns or "playerName" not in p.columns:
        return {}
    p["key"] = p["playerName"].astype(str).str.strip().str.lower()
    # if duplicates, keep first
    p = p.drop_duplicates(subset=["key"], keep="first")
    return dict(zip(p["key"], p["playerId"]))


def choose_tot_preferred(df: pd.DataFrame) -> pd.DataFrame:
    """
    For players who have multiple rows (multi-team), prefer TOT.
    If no TOT row, prefer the row with max mp.
    """
    out_rows = []
    for player, g in df.groupby("playerName", dropna=False):
        g2 = g.copy()
        # TOT is teamId == 'TOT'
        tot = g2[g2["teamId"].astype(str).str.upper() == "TOT"]
        if len(tot) > 0:
            out_rows.append(tot.iloc[0])
        else:
            if "mp" in g2.columns:
                out_rows.append(g2.sort_values("mp", ascending=False).iloc[0])
            else:
                out_rows.append(g2.iloc[0])
    return pd.DataFrame(out_rows).reset_index(drop=True)


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--input", default="raw_data/data.html", help="Path to BRef play-by-play share HTML (data.html)")
    ap.add_argument("--players", default="data/players.csv", help="Path to your players.csv (for playerId mapping)")
    ap.add_argument("--out", default="data/phase2_impact_misc_2025.csv", help="Output CSV path")
    ap.add_argument("--year", default="2025", help="Season year label to include")
    args = ap.parse_args()

    in_path = Path(args.input)
    if not in_path.exists():
        raise FileNotFoundError(f"Missing input HTML: {in_path}")

    df = load_bref_pbp_table(in_path)

    # Prefer TOT for multi-team players
    df = choose_tot_preferred(df)

    # Map playerId using your players.csv, fallback to deterministic
    id_map = load_player_id_map(Path(args.players))
    df["playerKey"] = df["playerName"].astype(str).str.strip().str.lower()
    df["playerId"] = df["playerKey"].map(id_map)

    # fallback id uses teamId (or "tot") + slugified name
    df["playerId"] = df["playerId"].fillna(
        df.apply(lambda r: f"bref_{str(r['teamId']).lower()}_{slugify(str(r['playerName']))}", axis=1)
    )

    df["season"] = int(args.year)

    # Final column order (keep it stable)
    keep = [
        "season",
        "playerId",
        "playerName",
        "teamId",
        "pos",
        "g",
        "mp",
        "onCourt_plusMinus_per100",
        "onOff_plusMinus_per100",
        "tov_badPass",
        "tov_lostBall",
        "tov_shoot",
        "tov_offensiveFoulOrOther",
        "foulsCommitted_shooting",
        "foulsCommitted_offensive",
        "foulsDrawn_shooting",
        "foulsDrawn_offensive",
        "misc_pga",
        "misc_and1",
        "misc_blkd",
    ]
    # only keep columns that exist (in case BRef changes slightly)
    keep = [c for c in keep if c in df.columns]
    out_df = df[keep].copy()

    out_path = Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(out_path, index=False, encoding="utf-8")

    print(f"Wrote {len(out_df)} rows -> {out_path}")


if __name__ == "__main__":
    main()
